{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "16b8da034ad25b7b8fd61059a656dc76f9db5db514f76d6455b71cd96f504458"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from moviepy.editor import VideoFileClip, concatenate\n",
    "from moviepy.editor import *\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'video.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip(input_file)#.subclip(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 44000\n",
    "a = 0.3\n",
    "b = 10\n",
    "out_name = 'cut_not' + '.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = clip.audio.subclip(10,20).to_soundarray(fps=10000)[:,0] # only get one of the soundvawes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = clip.audio.to_soundarray(fps=fps)[:,0] # only get one of the soundvawes\n",
    "y = np.abs(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_silent_parts(a, b, silence=0.01):\n",
    "    a_frames = int(a * fps)\n",
    "\n",
    "    # whether frames from i*a_frames:(i+1)*a_frames are sounded\n",
    "    # which is equal to i-seconds:i+a-seconds\n",
    "    sounds = []\n",
    "\n",
    "    current = 0\n",
    "\n",
    "    for i in range(0,len(y),a_frames): # len(y)\n",
    "        interval = y[i : i + a_frames]\n",
    "\n",
    "        split_intervals = np.array(np.split(interval,b))\n",
    "\n",
    "        means = split_intervals.mean(axis=1)\n",
    "\n",
    "        silent = means < silence\n",
    "\n",
    "\n",
    "        new_silent = np.all(silent)\n",
    "\n",
    "        if not current:\n",
    "            new_silent == 0\n",
    "\n",
    "        sounds.append(new_silent)\n",
    "\n",
    "        current = new_silent\n",
    "\n",
    "        \"\"\" plt.plot(interval)\n",
    "        plt.plot([(x+1/2)*a_frames/b for x in range(b)], means) \"\"\"\n",
    "\n",
    "    return np.invert(sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSecondsTuples():\n",
    "    sounds_array = get_non_silent_parts(a,b)\n",
    "    areas = []\n",
    "\n",
    "    current = False\n",
    "    current_start = 0\n",
    "\n",
    "    for i in range(len(sounds_array)):\n",
    "\n",
    "        if sounds_array[i]:\n",
    "            if not current:\n",
    "                current_start = i\n",
    "                current = True\n",
    "        else:\n",
    "            if current:\n",
    "                areas.append((current_start*a,(i)*a))\n",
    "            current = 0\n",
    "\n",
    "    if current:\n",
    "        areas.append((current_start*a,(len(sounds_array))*a))\n",
    "\n",
    "    return areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffmpeg_text():\n",
    "    tups_array = getSecondsTuples()\n",
    "    text = f\"select='{'+'.join([f'between(t,{tup[0]},{tup[1]})' for tup in tups_array])}'\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ffmpeg_script():\n",
    "    text = ffmpeg_text()\n",
    "    os.system(\n",
    "        f\"\"\"ffmpeg -i {input_file} \\\n",
    "       -vf \"{text},\n",
    "            setpts=N/FRAME_RATE/TB\" \\\n",
    "       -af \"a{text},\n",
    "            asetpts=N/SR/TB\" fast -y {out_name}\"\"\"\n",
    "    )\n",
    "run_ffmpeg_script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeNewVideo():\n",
    "    sounds = get_non_silent_parts(a,b)\n",
    "    timestamps = np.arange(0,clip.duration,a)\n",
    "    new_videos = np.array([clip.subclip(i,i+a) for i,x in zip(timestamps,sounds) if x])\n",
    "    return concatenate(new_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makeNewVideo().write_videofile(out_name, threads = 4,logger = None)"
   ]
  }
 ]
}